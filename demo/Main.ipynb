{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, ConfusionMatrixDisplay, roc_curve, auc, roc_auc_score\n",
    "from itertools import cycle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_dir = \"D:/MLUP Proejct/Alzheimer_s Dataset\"\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=data_transforms['train'])\n",
    "test_dataset = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=data_transforms['test'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18 and modify the final layer\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase epochs to 50\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    model.train()\n",
    "    best_accuracy = 0.0\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    train_precision = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        true_positives = 0\n",
    "        predicted_positives = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            true_positives += ((predicted == labels) & (predicted == 1)).sum().item()\n",
    "            predicted_positives += (predicted == 1).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        epoch_precision = 100 * true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "        \n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        train_loss.append(epoch_loss)\n",
    "        train_acc.append(epoch_acc)\n",
    "        train_precision.append(epoch_precision)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%, Precision: {epoch_precision:.2f}%, Time: {time.time()-start_time:.2f}s\")\n",
    "        \n",
    "        if epoch_acc > best_accuracy:\n",
    "            best_accuracy = epoch_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    torch.save(model.state_dict(), 'final_model.pth')\n",
    "    print(\"Training Complete. Best Accuracy: {:.2f}%\".format(best_accuracy))\n",
    "    plot_training_curves(train_loss, train_acc, train_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with precision and confusion matrix\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true_positives = 0\n",
    "    predicted_positives = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            true_positives += ((predicted == labels) & (predicted == 1)).sum().item()\n",
    "            predicted_positives += (predicted == 1).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    precision = 100 * true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test Precision: {precision:.2f}%\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(all_labels, all_preds)\n",
    "    # Plot precision-recall curve\n",
    "    plot_precision_recall_curve(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss, accuracy, and precision\n",
    "def plot_training_curves(train_loss, train_acc, train_precision):\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, train_loss, 'r-', label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss vs. Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, train_acc, 'b-', label=\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Training Accuracy vs. Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Precision Plot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, train_precision, 'g-', label=\"Training Precision\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Precision (%)\")\n",
    "    plt.title(\"Training Precision vs. Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(labels, preds):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Mild\", \"Moderate\", \"Non\", \"VeryMild\"])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot precision-recall curve (simplified for multiclass)\n",
    "def plot_precision_recall_curve(labels, preds):\n",
    "    # Convert to binary for simplicity (e.g., class 1 vs rest)\n",
    "    labels_bin = [1 if x == 1 else 0 for x in labels]\n",
    "    preds_bin = [1 if x == 1 else 0 for x in preds]\n",
    "    precision, recall, _ = precision_recall_curve(labels_bin, preds_bin)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve (Class 1 vs Rest)\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC-AUC curve for multiclass classification\n",
    "def plot_roc_auc_curve(labels, preds, num_classes=4):\n",
    "    labels_one_hot = np.eye(num_classes)[labels]\n",
    "    preds_one_hot = np.eye(num_classes)[preds]\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels_one_hot[:, i], preds_one_hot[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    colors = cycle(['blue', 'red', 'green', 'purple'])\n",
    "    for i, color in zip(range(num_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC-AUC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate model with ROC-AUC\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true_positives = 0\n",
    "    predicted_positives = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            true_positives += ((predicted == labels) & (predicted == 1)).sum().item()\n",
    "            predicted_positives += (predicted == 1).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    precision = 100 * true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test Precision: {precision:.2f}%\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(all_labels, all_preds)\n",
    "    # Plot precision-recall curve\n",
    "    plot_precision_recall_curve(all_labels, all_preds)\n",
    "    # Plot ROC-AUC curve\n",
    "    plot_roc_auc_curve(all_labels, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=50)\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymlup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
